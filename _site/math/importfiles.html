<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Importing Text Files with Python</title>
    
    <link href="/css/common.css" rel="stylesheet">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
  </head>
  <body>
    <div class = "titledate">
    <h1>Importing Text Files with Python</h1>
    <h2>23 January 2019</h2>
    </div>
    <div class = "narration">
      <p>A very common method of storing text information is within .txt files. To process this information, Python has to open and read the text files.</p>

<p>file = open(pathtofile, “r”)
data = file.read()</p>

<p>The contents of the file are now in the data variable.</p>

<p>Additionally we can append the contents of other files to the same data variable.</p>

<p>file = open(pathtoanotherfile, “r”)
data.append(file.read())</p>

<p>Through the use of loops, we can rapidly give Python our text information, even if its spread out among many files.</p>

<p>The function len(data) returns the number of characters in the variable. This information is interesting. We could analyze the frequency of letters, punctuation marks, and spaces. However, a lot of text analysis requires the data to be separated into words or sentences.</p>

<p>Splitting raw text into words and sentences is harder than it initially seems. This is caused by the versatility of language. In most cases, a period signifies the end of a sentence but if we’re talking about Mt. Kilimanjaro it does not.</p>

<p>Thankfully much of the heavy lifting has been done already. Libraries such as the Natural Language Toolkit have the capability to segment sentences with more accuracy than we could manage ourselves.</p>

<p>This process is known as Tokenization.</p>


    </div>
  </body>
</html>