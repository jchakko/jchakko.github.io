<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Precision and Recall</title>
    
    <link href="/css/common.css" rel="stylesheet">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
  </head>
  <body>
    <h1>Precision and Recall</h1>
    <p>10 February 2019</p>
      <div id = "postContents"> 
  <h2>Precision</h2>
  <h3>What percentage of cases predicted to be positive are actually positive? This metric considers the accuracy of the model when it flags something. It is the ratio if True Postiives / (True Positives + False Positives)</h3>
  
  <h2>Recall</h2>
  <h3>What percentage of flag worthy cases were actually marked by the model? This metric considers the model's ability to correctly identify positive cases. It is the ratio of True Positives / (True Positives + False Negatives)</h3>
  
  <h2>The Significance</h2>
  <h3>These metrics are important because its possible to maintain a high raw accuracy without doing anything in certain cases. Imagine trying to detect meteors that only appear every hundred years. If the model simply said there was no meteor every night the accuracy and precision would be high. However, the recall would be terrible since it wouldn't declare meteors even if they were visible.</h3>
  
  <h2>Application</h2>
  <h3>These metrics can be used to calculate F1 Score</h3>
  </div>
</body>
</html>


  </body>
</html>